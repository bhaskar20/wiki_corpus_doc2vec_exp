{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Wiki loaded\n",
      "2020-01-26 15:52:30.225856\n",
      "0:00:28.291065\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting\")\n",
    "print(\"Wiki loaded\")\n",
    "print(datetime.datetime.now())\n",
    "print(datetime.datetime.now() - start)\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = WikiCorpus(\"./data/enwiki-latest-pages-articles1.xml-p10p30302.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedWikiDocument(object):\n",
    "    def __init__(self, wiki):\n",
    "        self.wiki = wiki\n",
    "        self.wiki.metadata = True\n",
    "    def __iter__(self):\n",
    "        for content, (page_id, title) in self.wiki.get_texts():\n",
    "            yield TaggedDocument(content, [title])\n",
    "            \n",
    "class EpochLoggerDBOW(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = TaggedWikiDocument(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Doc2Vec(min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = Doc2Vec(min_count=0)\n",
    "# pre.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num in range(0, 20):\n",
    "#     print('min_count: {}, size of vocab: '.format(num), pre.scale_vocab(min_count=num, dry_run=True)['memory']['vocab']/700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/myenv/lib/python3.6/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/home/ubuntu/anaconda3/envs/myenv/lib/python3.6/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "models = [\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, dbow_words=1, size=200, window=8, min_count=19, iter=10, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=200, window=8, min_count=19, iter =10, workers=cores),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d200,n5,w8,mc19,s0.001,t16)\n",
      "Doc2Vec(dm/m,d200,n5,w8,mc19,s0.001,t16)\n"
     ]
    }
   ],
   "source": [
    "models[0].build_vocab(documents)\n",
    "print(str(models[0]))\n",
    "models[1].reset_from(models[0])\n",
    "print(str(models[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.train(documents, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "temp_path_dbow = get_tmpfile('DBOW_epoch7.model')\n",
    "# models[0].save(temp_path_dbow)\n",
    "# temp_path_db = get_tmpfile('wiki_d2v_db')\n",
    "# models[1].save(temp_path_db)\n",
    "\n",
    "model_dbow = Doc2Vec.load(temp_path_dbow)\n",
    "# model_db = Doc2Vec.load(temp_path_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Supervised learning', 0.6636233925819397),\n",
      " ('Pattern recognition', 0.6623779535293579),\n",
      " ('Outline of machine learning', 0.6366842985153198),\n",
      " ('Deep learning', 0.6187774538993835),\n",
      " ('Artificial neural network', 0.612984836101532),\n",
      " ('Unsupervised learning', 0.6096498966217041),\n",
      " ('Feature selection', 0.6061097383499146),\n",
      " ('Boosting (machine learning)', 0.6051622033119202),\n",
      " ('Predictive analytics', 0.6042125821113586),\n",
      " ('Data mining', 0.602078378200531),\n",
      " ('Artificial intelligence', 0.592949390411377),\n",
      " ('Bayesian network', 0.5902780294418335),\n",
      " ('Linear classifier', 0.585090160369873),\n",
      " ('Outline of computer science', 0.5741325616836548),\n",
      " ('Symbolic artificial intelligence', 0.5736307501792908),\n",
      " ('Glossary of artificial intelligence', 0.5702601671218872),\n",
      " ('Deeplearning4j', 0.5696315765380859),\n",
      " ('Early stopping', 0.5691721439361572),\n",
      " ('Latent semantic analysis', 0.568435788154602),\n",
      " ('Neural Designer', 0.5665047764778137)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b0a32033493b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Machine learning\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Machine learning\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_db' is not defined"
     ]
    }
   ],
   "source": [
    "# similarity\n",
    "# for model in models:\n",
    "#     print(str(model))\n",
    "#     pprint(model.docvecs.most_similar(positive=[\"Machine learning\"], topn=20))\n",
    "\n",
    "pprint(model_dbow.docvecs.most_similar(positive=[\"Machine learning\"], topn=20))\n",
    "# pprint(model_db.docvecs.most_similar(positive=[\"Machine learning\"], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Effective sample size', 0.6514292359352112),\n",
      " ('Less-is-more effect', 0.6494983434677124),\n",
      " ('Maximum common subgraph', 0.6433039903640747),\n",
      " ('S-procedure', 0.6417062282562256),\n",
      " (\"Cohen's h\", 0.6371748447418213),\n",
      " ('Intensity (measure theory)', 0.6349696516990662),\n",
      " ('Predictive mean matching', 0.6315295696258545),\n",
      " ('Accuracy paradox', 0.6308474540710449),\n",
      " ('Numerical value equation', 0.628330409526825),\n",
      " ('Dichotomous thinking', 0.6268120408058167),\n",
      " ('Sub-probability measure', 0.6241165399551392),\n",
      " ('Elbow method (clustering)', 0.6229354739189148),\n",
      " (\"Bendixson's inequality\", 0.6215020418167114),\n",
      " ('C+-probability', 0.6206342577934265),\n",
      " ('Heptadiagonal matrix', 0.6195244789123535),\n",
      " ('Intensity measure', 0.6192264556884766),\n",
      " ('Binomial process', 0.6188932657241821),\n",
      " ('Indicator vector', 0.6173559427261353),\n",
      " ('Simple point process', 0.6162580251693726),\n",
      " ('Event structure', 0.6128488779067993)]\n",
      "[('estimand', 0.5939438939094543),\n",
      " ('discrepancy', 0.5844589471817017),\n",
      " ('probability', 0.5767028331756592),\n",
      " ('supracontext', 0.5723075866699219),\n",
      " ('strategyproof', 0.5646688342094421),\n",
      " ('frequentists', 0.5642316341400146),\n",
      " ('probabilities', 0.5617425441741943),\n",
      " ('automorphically', 0.5551148056983948),\n",
      " ('dimensionful', 0.5551074743270874),\n",
      " ('eviu', 0.5550411939620972),\n",
      " ('ordinality', 0.554888904094696),\n",
      " ('equiprobable', 0.5546644330024719),\n",
      " ('pseudocounts', 0.5514082908630371),\n",
      " ('statistically', 0.5477718114852905),\n",
      " ('constraint', 0.546645998954773),\n",
      " ('duocentric', 0.5432174205780029),\n",
      " ('truthful', 0.543189525604248),\n",
      " ('vglms', 0.5380096435546875),\n",
      " ('upcards', 0.5357747077941895),\n",
      " ('underinsurance', 0.5351982116699219)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "text = 'Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.[1][2]:2 Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.'\n",
    "text1 = 'Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead'\n",
    "text2 = 'The name machine learning was coined in 1959 by Arthur Samuel.[5] Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[6] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing\\'s proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[7] In Turing\\'s proposal the various characteristics that could be possessed by a thinking machine and the various implications in constructing one are exposed.'\n",
    "text3 = 'Implicit computational complexity (ICC) is a subfield of computational complexity theory that characterizes algorithms by constraints on the way in which they are constructed, without reference to a specific underlying machine model or to explicit bounds on computational resources unlike conventional complexity theory. ICC was developed in the 1990s and employs the techniques of proof theory, substructural logic, model theory and recursion theory to prove bounds on the expressive power of high-level formal languages. ICC is also concerned with the practical realization of functional programming languages, language tools and type theory that can control the resource usage of programs in a formally verifiable sense.'\n",
    "text4 = 'Quantum artificial intelligence (QAI) is an interdisciplinary field that focuses on building quantum algorithms for improving computational tasks within artificial intelligence, including sub-fields like machine learning.Quantum mechanics phenomena, superposition and entanglement, are allowing quantum computing to perform computations which are much more efficient than classical AI algorithms used in computer vision, natural language processing and robotics.[1] The entire concept of quantum-enhanced AI algorithms is still in conceptual research domain. Building on recent theoretical proposals, initial practical studies suggest that these concepts have the possibility to be implemented in the laboratory, under strictly controlled conditions.[2]'\n",
    "text5='Applying classical methods of machine learning to the study of quantum systems (sometimes called quantum machine learning) is the focus of an emergent area of physics research. A basic example of this is quantum state tomography, where a quantum state is learned from measurement. Other examples include learning Hamiltonians[1], learning quantum phase transitions[2][3], and automatically generating new quantum experiments[4][5][6][7]. Classical machine learning is effective at processing large amounts of experimental or calculated data in order to characterize an unknown quantum system, making its application useful in contexts including quantum information theory, quantum technologies development, and computational materials design.'\n",
    "text6='MatrixNet is a proprietary machine learning algorithm developed by Yandex and used widely throughout the company products. The algorithm is based on gradient boosting and was introduced since 2009.[1][2][3]'\n",
    "text7='Yandex N.V. (/ˈjʌndɛks/; Russian: Яндекс, IPA: [ˈjandəks]) is a Russian multinational corporation specializing in Internet-related products and services, including transportation, search and information services, eCommerce, navigation, mobile applications, and online advertising. Yandex provides over 70 services in total.[5][6] Incorporated in the Netherlands, Yandex primarily serves audiences in Russia and the Commonwealth of Independent States. The company founders and most of the team members are located in Russia. The company has 18 commercial offices worldwide.[7][8] It is the largest technology company in Russia[9] and the largest search engine on the internet in Russian, with a market share of over 52%.[10] The Yandex.ru home page is the 4th most popular website in Russia.[11] It also has the largest market share of any search engine in the Commonwealth of Independent States and is the 5th largest search engine worldwide after Google, Baidu, Bing, and Yahoo!.'\n",
    "text8='In the nervous system, a synapse[2] is a structure that permits a neuron (or nerve cell) to pass an electrical or chemical signal to another neuron or to the target effector cell.Santiago Ramón y Cajal proposed that neurons are not continuous throughout the body, yet still communicate with each other, an idea known as the neuron doctrine.[3] The word \"synapse\" – from the Greek synapsis (συνάψις), meaning \"conjunction\", in turn from συνάπτεὶν (συν (\"together\") and ἅπτειν (\"to fasten\")) – was introduced in 1897 by the English neurophysiologist Charles Sherrington in Michael Foster\\'s Textbook of Physiology.[2] Sherrington struggled to find a good term that emphasized a union between two separate elements, and the actual term \"synapse\" was suggested by the English classical scholar Arthur Woollgar Verrall, a friend of Foster.[4][5] Some authors generalize the concept of the synapse to include the communication from a neuron to any other cell type,[6] such as to a motor cell, although such non-neuronal contacts may be referred to as junctions (a historically older term).A landmark study by Sanford Palay demonstrated the existence of synapses.[7]Synapses are essential to neuronal function: neurons are cells that are specialized to pass signals to individual target cells, and synapses are the means by which they do so. At a synapse, the plasma membrane of the signal-passing neuron (the presynaptic neuron) comes into close apposition with the membrane of the target (postsynaptic) cell. Both the presynaptic and postsynaptic sites contain extensive arrays of molecular machinery that link the two membranes together and carry out the signaling process. In many synapses, the presynaptic part is located on an axon and the postsynaptic part is located on a dendrite or soma. Astrocytes also exchange information with the synaptic neurons, responding to synaptic activity and, in turn, regulating neurotransmission.[8] Synapses (at least chemical synapses) are stabilized in position by synaptic adhesion molecules (SAMs) projecting from both the pre- and post-synaptic neuron and sticking together where they overlap; SAMs may also assist in the generation and functioning of synapses.[9]'\n",
    "text9 = 'Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[28]Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library.[29]'\n",
    "text10 = 'Python was conceived in the late 1980s[34] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC language (itself inspired by SETL),[35] capable of exception handling and interfacing with the Amoeba operating system.[8] Its implementation began in December 1989.[36] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python\\'s Benevolent Dictator For Life, a title the Python community bestowed upon him to reflect his long-term commitment as the project\\'s chief decision-maker.[37] He now shares his leadership as a member of a five-person steering council.[38][39][40] In January 2019, active Python core developers elected Brett Cannon, Nick Coghlan, Barry Warsaw, Carol Willing and Van Rossum to a five-member \"Steering Council\" to lead the project.[41]Python 2.0 was released on 16 October 2000 with many major new features, including a cycle-detecting garbage collector and support for Unicode.[42]Python 3.0 was released on 3 December 2008. It was a major revision of the language that is not completely backward-compatible.[43] Many of its major features were backported to Python 2.6.x[44] and 2.7.x version series. Releases of Python 3 include the 2to3 utility, which automates (at least partially) the translation of Python 2 code to Python 3.[45]'\n",
    "text11 = 'You don\\'t mention the size of your dataset - in rows, total words, unique words, or unique classes. Doc2Vec works best with lots of data. Most published work trains on tens-of-thousands to millions of documents, of dozens to thousands of words each. (Your data appears to only have 3-5 words per document.)Also, published work tends to train on data where every document has a unique-ID. It can sometimes make sense to use known-labels as tags instead of, or in addition to, unique-IDs. But it isn\\'t necessarily a better approach. By using known-labels as the only tags, you\\'re effectively only training one doc-vector per label. (It\\'s essentially similar to concatenating all rows with the same tag into one document.)'\n",
    "text12 = 'Multisignature (multi-signature) is a digital signature scheme which allows a group of users to sign a single document. Usually, a multisignature algorithm produces a joint signature that is more compact than a collection of distinct signatures from all users.[1]Multisignature can be considered as generalization of both group and ring signatures.Multisignature adds additional security for cryptocurrency transactions.'\n",
    "text13 = 'Probability is a numerical description of how likely an event is to occur or how likely it is that a proposition is true. Probability is a number between 0 and 1, where, roughly speaking, 0 indicates impossibility and 1 indicates certainty.[note 1][1][2] The higher the probability of an event, the more likely it is that the event will occur. A simple example is the tossing of a fair (unbiased) coin. Since the coin is fair, the two outcomes (\"heads\" and \"tails\") are both equally probable; the probability of \"heads\" equals the probability of \"tails\"; and since no other outcomes are possible, the probability of either \"heads\" or \"tails\" is 1/2 (which could also be written as 0.5 or 50%).'\n",
    "pprint(model_dbow.docvecs.most_similar([model_dbow.infer_vector(text13.split())], topn=20))\n",
    "pprint(model_dbow.similar_by_vector(model_dbow.infer_vector(text13.split()), topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('time', 0.5998595952987671),\n",
      " ('run', 0.577658474445343),\n",
      " ('rank', 0.5759809017181396),\n",
      " ('place', 0.5707610845565796),\n",
      " ('event', 0.5684378147125244),\n",
      " ('name', 0.5597543716430664),\n",
      " ('world', 0.5573016405105591),\n",
      " ('final', 0.5564603805541992),\n",
      " ('cross', 0.5534589290618896),\n",
      " ('girls', 0.5459471940994263),\n",
      " ('individual', 0.5344840288162231),\n",
      " ('did', 0.5329700708389282),\n",
      " ('women', 0.5327101945877075),\n",
      " ('number', 0.5314116477966309),\n",
      " ('events', 0.5307267308235168),\n",
      " ('same', 0.5268730521202087),\n",
      " ('started', 0.5253022313117981),\n",
      " ('third', 0.5245479345321655),\n",
      " ('last', 0.5243156552314758),\n",
      " ('references', 0.523186445236206)]\n"
     ]
    }
   ],
   "source": [
    "pprint(model_dbow.wv.most_similar(positive=[\"country\"], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "pprint(model_dbow.vocabulary.make_cum_table(model_dbow.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
